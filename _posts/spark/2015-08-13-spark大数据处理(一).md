---
layout: post
category : spark
tagline: ""
tags : [spark]
---
{% include JB/setup %}

### 前言
刚好需要在公司给同事做个spark大数据处理方面的分享，于是做个了整理写在博客里。<br/>
前段时间将公司日志分析系统的实时分析由storm迁移到了spark-streaming,定时任务也全部换成了spark来计算。已经在线上跑了几个月
总体还算稳定。<br/>
公司用到spark版本是CDH的1.3.0。这里不讲spark的安装过程<br/>
demo 由java来实现 并没有选择原生的scala 代码：https://github.com/haluo/SparkDemoJava<br/>

### 简介

Spark是继Hadoop之后的新一代大数据分布式处理框架：
Apache顶级项目
2014大数据领域最活跃开源项目
应用  百度/阿里/腾讯/京东。。。

核心组件：

Spark core 用于Batch数据处理（对应于hadoop的map reduce）
Spark streaming用于处理实时的流数据(对应于storm)
Spark SQL通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI和可视化工具在Spark数据上执行类似SQL的查询
Spark MLlib: Spark机器学习库
Spark GraphX:是用于图计算和并行图计算的 新的（alpha）Spark API。

同类产品比较：
Spark core相对于hadoop mr:
1.基于内存的迭代计算，中间结果缓存在内存中
	-hadoop mr Shuffle 会有大量磁盘IO
2.丰富的API（map reduce, group by ,sort by 等） 满足   不同的需求,编程更简单
	-hadoop mr只有map 和 reduce 太抽象
3. 分区相同的转换操作构成流水线在同一个task中完成，分区不同的转换需要shuffle.需要等前面的任务完成后才可以开始。
	- hadoop mr的所有reduce都需要等map执行完成后才能开始


Spark streaming相对于storm:
1.吞吐量高
2.将流拆成小的batch数据来处理流数据,实时性没storm好










